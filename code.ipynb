{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04a8bd47",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ff930cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe924d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "466d85e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30b6d3f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense , Activation , Dropout ,Flatten,  MaxPooling2D, Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "019f9074",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = (r'C:\\Users\\SAMRIDHI SAHU\\code\\PastWork\\code\\Facial-Emotion-Recognition-main\\data\\ckplus\\CK+48')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "006ebf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path, environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebced87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 classes are ['anger', 'contempt', 'disgust', 'fear', 'happy', 'sadness', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "data_dir_list = os.listdir(data_path)\n",
    "#data_dir_list\n",
    "print(str(len(data_dir_list))+' classes are',data_dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52875106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f76f6e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images in anger =  135\n",
      "number of images in contempt =  54\n",
      "number of images in disgust =  177\n",
      "number of images in fear =  75\n",
      "number of images in happy =  207\n",
      "number of images in sadness =  84\n",
      "number of images in surprise =  249\n"
     ]
    }
   ],
   "source": [
    "img_data = []\n",
    "for dataset in data_dir_list:\n",
    "    img_list = os.listdir(data_path+'/'+dataset)\n",
    "    print('number of images in '+str(dataset)+' = ',len(img_list))\n",
    "    for img in img_list:\n",
    "        img = cv2.imread(data_path+'/'+dataset+'/'+img)\n",
    "        \n",
    "        img = cv2.resize(img,(48,48))\n",
    "        \n",
    "        img_data.append(img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b11302a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc13ae28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data = np.array(img_data)\n",
    "img_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54180af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(981, 48, 48, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bdfd4238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization (essential for neural nets)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data = img_data/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c92bfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(981, 48, 48, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec29740f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of image (48, 48)\n",
      "num of images  981\n"
     ]
    }
   ],
   "source": [
    "print('shape of image', (img_data.shape[1],img_data.shape[2]))\n",
    "print('num of images ', img_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd497c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_text = {0:'anger', 1:'contempt', 2: 'contempt',\n",
    "                         3:'fear', 4:'happiness',\n",
    "                         5: 'sadness', 6: 'surprise'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ba1ce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.ones((img_data.shape[0],),dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ede8f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0:134]=0 #135\n",
    "labels[135:188]=1 #54\n",
    "labels[189:365]=2 #177\n",
    "\n",
    "labels[366:440]=3 #75\n",
    "labels[441:647]=4 #207\n",
    "\n",
    "labels[648:731]=5 #84\n",
    "labels[732:980]=6 #249"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3942af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images_arr):\n",
    "    fig,axes = plt.subplots(1,1,figsize=(5,5))\n",
    "#     axes = axes.flatten()\n",
    "    axes.imshow(images_arr)\n",
    "    axes.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c20c8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happiness\n"
     ]
    }
   ],
   "source": [
    "plotImages(img_data[600])\n",
    "print(label_text[labels[600]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "82ebd39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optim):\n",
    "    input_shape=(48,48,3)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(6, (5, 5), input_shape=input_shape, padding='same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(16, (5, 5), padding='same', activation = 'relu'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(7, activation = 'softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=optim)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d49ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31d64863",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "                        height_shift_range=0.1, shear_range=0.2,\n",
    "                        zoom_range=0.2, horizontal_flip=True,\n",
    "                        fill_mode='nearrest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "24224a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "61fd2cce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x,Y \u001b[38;5;241m=\u001b[39m shuffle(img_data, \u001b[43mY\u001b[49m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y' is not defined"
     ]
    }
   ],
   "source": [
    "x,Y = shuffle(img_data, Y, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5531090c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [54], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mx\u001b[49m, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      2\u001b[0m x_test\u001b[38;5;241m=\u001b[39mX_test\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
    "x_test=X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "869fe318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = utils.to_categorical(labels, len(dataset)-1)\n",
    "print(len(Y))\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b4f7ad13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "981"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "643e2480",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plotImages(\u001b[43mx\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(y[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "plotImages(x[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830c4eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e3657f12",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [58], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m aug\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "aug.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "11715491",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0.00005,\n",
    "    patience=11,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=7,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    early_stopping,\n",
    "    lr_scheduler,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f09f2005",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #batch size of 32 performs the best.\n",
    "epochs = 100\n",
    "optims = [\n",
    "    Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name='Nadam'),\n",
    "    Adam(0.001),\n",
    "]\n",
    "\n",
    "\n",
    "model = create_model(optims[1]) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "38f0c5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 6)         456       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 6)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 16)        2416      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 24, 24, 16)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 64)        9280      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               204928    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 217,983\n",
      "Trainable params: 217,983\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "518515b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [62], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39m\u001b[43mX_train\u001b[49m, y\u001b[38;5;241m=\u001b[39m y_train, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, \n\u001b[0;32m      2\u001b[0m           epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39mcallbacks \n\u001b[0;32m      3\u001b[0m          )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(x=X_train, y= y_train, validation_split=0.1, batch_size=32, \n",
    "          epochs=100, shuffle=True, verbose=2, callbacks=callbacks \n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "311b01d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [63], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_classes\u001b[49m(X_test)\n\u001b[0;32m      3\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(np\u001b[38;5;241m.\u001b[39mwhere(y_test \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m], results)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "results = model.predict_classes(X_test)\n",
    "cm = confusion_matrix(np.where(y_test == 1)[1], results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "29bae4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9a547ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapdisgust = ['anger','contempt','disgust','fear','happy','sadness','surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0d85781e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [66], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cm_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mcm\u001b[49m, index \u001b[38;5;241m=\u001b[39m label_mapdisgust,\n\u001b[0;32m      2\u001b[0m                      columns \u001b[38;5;241m=\u001b[39m label_mapdisgust\n\u001b[0;32m      3\u001b[0m                     )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cm' is not defined"
     ]
    }
   ],
   "source": [
    "cm_df = pd.DataFrame(cm, index = label_mapdisgust,\n",
    "                     columns = label_mapdisgust\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c0f5f090",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [67], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(\u001b[43mcm\u001b[49m, annot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGreys\u001b[39m\u001b[38;5;124m'\u001b[39m,cbar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNN Emotion Classify\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue class\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cm' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (5,5))\n",
    "sns.heatmap(cm, annot = True,cmap='Greys',cbar=False,linewidth=2,fmt='d')\n",
    "plt.title('CNN Emotion Classify')\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Prediction class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f66edb2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m score \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(\u001b[43mX_test\u001b[49m, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Loss:\u001b[39m\u001b[38;5;124m'\u001b[39m, score[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest accuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m, score[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "test_image = X_test[3:4]\n",
    "print (test_image.shape)\n",
    "\n",
    "print(model.predict(test_image))\n",
    "print(model.predict_classes(test_image))\n",
    "print(y_test[3:4])\n",
    "\n",
    "#predict\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "286cc0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7aed9688",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [70], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m (\u001b[43my_pred\u001b[49m\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m      2\u001b[0m multilabel_confusion_matrix(y_test, y_pred )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = (y_pred>0.5)\n",
    "multilabel_confusion_matrix(y_test, y_pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "60095cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images in anger =  135\n",
      "number of images in contempt =  54\n",
      "number of images in disgust =  177\n",
      "number of images in fear =  75\n",
      "number of images in happy =  207\n",
      "number of images in sadness =  84\n",
      "number of images in surprise =  249\n"
     ]
    }
   ],
   "source": [
    "for dataset in data_dir_list:\n",
    "    img_list = os.listdir(data_path+'/'+dataset)\n",
    "    print('number of images in '+str(dataset)+' = ',len(img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c38e0839",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [72], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plotImages(\u001b[43mX_test\u001b[49m[\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m      2\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(model\u001b[38;5;241m.\u001b[39mpredict_classes(test_image)[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(label_text[ans])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "plotImages(X_test[3])\n",
    "ans = int(model.predict_classes(test_image)[0])\n",
    "print(label_text[ans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "322a4807",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('model.h5') is False:\n",
    "    model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4ed52698",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [74], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_img \u001b[38;5;241m=\u001b[39m \u001b[43mX_test\u001b[49m[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_img\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m plotImages(X_test[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "test_img = X_test[1:2]\n",
    "print(test_img.shape)\n",
    "plotImages(X_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c56e763f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_classes\u001b[49m(test_img)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "model.predict_classes(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6712cc27",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [76], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43my_test\u001b[49m[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "y_test[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "900cc088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = []\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "11d751cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imageio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [78], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimageio\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imageio'"
     ]
    }
   ],
   "source": [
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4ca56662",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imageio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [79], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pic \u001b[38;5;241m=\u001b[39m \u001b[43mimageio\u001b[49m\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mex7.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'imageio' is not defined"
     ]
    }
   ],
   "source": [
    "pic = imageio.imread('ex7.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "05c0fa71",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [80], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpic\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pic' is not defined"
     ]
    }
   ],
   "source": [
    "pic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "53058b7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [81], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pic \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(\u001b[43mpic\u001b[49m,(\u001b[38;5;241m48\u001b[39m,\u001b[38;5;241m48\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pic' is not defined"
     ]
    }
   ],
   "source": [
    "pic = cv2.resize(pic,(48,48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ef0a122a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [82], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m xx\u001b[38;5;241m.\u001b[39mappend(\u001b[43mpic\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pic' is not defined"
     ]
    }
   ],
   "source": [
    "xx.append(pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "78b9368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.array(xx)\n",
    "xx = xx.astype('float32')\n",
    "xx = xx/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aed35870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7acfb0e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [85], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_classes\u001b[49m(xx)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "model.predict_classes(xx)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c6f285e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [86], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plotImages(\u001b[43mpic\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pic' is not defined"
     ]
    }
   ],
   "source": [
    "plotImages(pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2e5d68e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger', 'contempt', 'disgust', 'fear', 'happy', 'sadness', 'surprise']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343816b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1d1b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb60eb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6dc7b91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Select your choice: \n",
      "\n",
      " 1) Capture live feed using webcam\n",
      "\n",
      " 2) Select a video file \n",
      "\n",
      " 3) Select a image file \n",
      "\n",
      " Enter Your Choice :\n",
      "Choice: \n",
      "1\n",
      "Empty DataFrame\n",
      "Columns: [time, emotion]\n",
      "Index: []\n",
      "(0, 2)\n",
      "Series([], dtype: int64) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAMRIDHI SAHU\\opencv\\lib\\site-packages\\matplotlib\\axes\\_axes.py:3154: RuntimeWarning: invalid value encountered in divide\n",
      "  x = x / sx\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [89], line 152\u001b[0m\n\u001b[0;32m    147\u001b[0m         emo_count\u001b[38;5;241m.\u001b[39mremove(i)\n\u001b[0;32m    148\u001b[0m         emo_name\u001b[38;5;241m.\u001b[39mremove(j)\n\u001b[1;32m--> 152\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpie\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memo_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memo_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautopct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%1.2f\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstartangle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m90\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# print('\\n emo_count :',emo_count)\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# print('\\n emo_name :',emo_name)\u001b[39;00m\n\u001b[0;32m    158\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmotions Recorded \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\opencv\\lib\\site-packages\\matplotlib\\pyplot.py:2715\u001b[0m, in \u001b[0;36mpie\u001b[1;34m(x, explode, labels, colors, autopct, pctdistance, shadow, labeldistance, startangle, radius, counterclock, wedgeprops, textprops, center, frame, rotatelabels, normalize, data)\u001b[0m\n\u001b[0;32m   2708\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mpie)\n\u001b[0;32m   2709\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpie\u001b[39m(\n\u001b[0;32m   2710\u001b[0m         x, explode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, colors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, autopct\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2713\u001b[0m         textprops\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, center\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), frame\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   2714\u001b[0m         rotatelabels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 2715\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mpie(\n\u001b[0;32m   2716\u001b[0m         x, explode\u001b[38;5;241m=\u001b[39mexplode, labels\u001b[38;5;241m=\u001b[39mlabels, colors\u001b[38;5;241m=\u001b[39mcolors,\n\u001b[0;32m   2717\u001b[0m         autopct\u001b[38;5;241m=\u001b[39mautopct, pctdistance\u001b[38;5;241m=\u001b[39mpctdistance, shadow\u001b[38;5;241m=\u001b[39mshadow,\n\u001b[0;32m   2718\u001b[0m         labeldistance\u001b[38;5;241m=\u001b[39mlabeldistance, startangle\u001b[38;5;241m=\u001b[39mstartangle,\n\u001b[0;32m   2719\u001b[0m         radius\u001b[38;5;241m=\u001b[39mradius, counterclock\u001b[38;5;241m=\u001b[39mcounterclock,\n\u001b[0;32m   2720\u001b[0m         wedgeprops\u001b[38;5;241m=\u001b[39mwedgeprops, textprops\u001b[38;5;241m=\u001b[39mtextprops, center\u001b[38;5;241m=\u001b[39mcenter,\n\u001b[0;32m   2721\u001b[0m         frame\u001b[38;5;241m=\u001b[39mframe, rotatelabels\u001b[38;5;241m=\u001b[39mrotatelabels, normalize\u001b[38;5;241m=\u001b[39mnormalize,\n\u001b[0;32m   2722\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}))\n",
      "File \u001b[1;32m~\\opencv\\lib\\site-packages\\matplotlib\\__init__.py:1423\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1422\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1423\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(ax, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1425\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1426\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1427\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32m~\\opencv\\lib\\site-packages\\matplotlib\\axes\\_axes.py:3196\u001b[0m, in \u001b[0;36mAxes.pie\u001b[1;34m(self, x, explode, labels, colors, autopct, pctdistance, shadow, labeldistance, startangle, radius, counterclock, wedgeprops, textprops, center, frame, rotatelabels, normalize)\u001b[0m\n\u001b[0;32m   3193\u001b[0m x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m expl \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mcos(thetam)\n\u001b[0;32m   3194\u001b[0m y \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m expl \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39msin(thetam)\n\u001b[1;32m-> 3196\u001b[0m w \u001b[38;5;241m=\u001b[39m \u001b[43mmpatches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWedge\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m360.\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtheta1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3197\u001b[0m \u001b[43m                   \u001b[49m\u001b[38;5;241;43m360.\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtheta1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3198\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_next_color\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3199\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mclip_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3200\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3201\u001b[0m w\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mwedgeprops)\n\u001b[0;32m   3202\u001b[0m slices\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32m~\\opencv\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:454\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[0;32m    449\u001b[0m     warn_deprecated(\n\u001b[0;32m    450\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    451\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    453\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\opencv\\lib\\site-packages\\matplotlib\\patches.py:1193\u001b[0m, in \u001b[0;36mWedge.__init__\u001b[1;34m(self, center, r, theta1, theta2, width, **kwargs)\u001b[0m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtheta1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtheta2 \u001b[38;5;241m=\u001b[39m theta1, theta2\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_patch_transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mIdentityTransform()\n\u001b[1;32m-> 1193\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recompute_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\opencv\\lib\\site-packages\\matplotlib\\patches.py:1205\u001b[0m, in \u001b[0;36mWedge._recompute_path\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1202\u001b[0m     connector \u001b[38;5;241m=\u001b[39m Path\u001b[38;5;241m.\u001b[39mLINETO\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;66;03m# Form the outer ring\u001b[39;00m\n\u001b[1;32m-> 1205\u001b[0m arc \u001b[38;5;241m=\u001b[39m \u001b[43mPath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1208\u001b[0m     \u001b[38;5;66;03m# Partial annulus needs to draw the outer ring\u001b[39;00m\n\u001b[0;32m   1209\u001b[0m     \u001b[38;5;66;03m# followed by a reversed and scaled inner ring\u001b[39;00m\n\u001b[0;32m   1210\u001b[0m     v1 \u001b[38;5;241m=\u001b[39m arc\u001b[38;5;241m.\u001b[39mvertices\n",
      "File \u001b[1;32m~\\opencv\\lib\\site-packages\\matplotlib\\path.py:955\u001b[0m, in \u001b[0;36mPath.arc\u001b[1;34m(cls, theta1, theta2, n, is_wedge)\u001b[0m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# number of curve segments to make\u001b[39;00m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 955\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43meta2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meta1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhalfpi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn must be >= 1 or None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\opencv\\lib\\site-packages\\IPython\\core\\formatters.py:339\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[0;32m    341\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[1;32m~\\opencv\\lib\\site-packages\\IPython\\core\\pylabtools.py:151\u001b[0m, in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[0;32m    149\u001b[0m     FigureCanvasBase(fig)\n\u001b[1;32m--> 151\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mprint_figure(bytes_io, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    152\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\opencv\\lib\\site-packages\\matplotlib\\backend_bases.py:2318\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bbox_inches:\n\u001b[0;32m   2317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 2318\u001b[0m         bbox_inches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2319\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_extra_artists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox_extra_artists\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2320\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pad_inches \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2321\u001b[0m             pad_inches \u001b[38;5;241m=\u001b[39m rcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msavefig.pad_inches\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\opencv\\lib\\site-packages\\matplotlib\\figure.py:1733\u001b[0m, in \u001b[0;36mFigureBase.get_tightbbox\u001b[1;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[0;32m   1730\u001b[0m     artists \u001b[38;5;241m=\u001b[39m bbox_extra_artists\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m-> 1733\u001b[0m     bbox \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1735\u001b[0m         bb\u001b[38;5;241m.\u001b[39mappend(bbox)\n",
      "File \u001b[1;32m~\\opencv\\lib\\site-packages\\matplotlib\\axes\\_base.py:4450\u001b[0m, in \u001b[0;36m_AxesBase.get_tightbbox\u001b[1;34m(self, renderer, call_axes_locator, bbox_extra_artists, for_layout_only)\u001b[0m\n\u001b[0;32m   4447\u001b[0m     bbox_artists \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_default_bbox_extra_artists()\n\u001b[0;32m   4449\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m bbox_artists:\n\u001b[1;32m-> 4450\u001b[0m     bbox \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4451\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (bbox \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4452\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m bbox\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m<\u001b[39m np\u001b[38;5;241m.\u001b[39minf\n\u001b[0;32m   4453\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m bbox\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m<\u001b[39m np\u001b[38;5;241m.\u001b[39minf):\n\u001b[0;32m   4454\u001b[0m         bb\u001b[38;5;241m.\u001b[39mappend(bbox)\n",
      "File \u001b[1;32m~\\opencv\\lib\\site-packages\\matplotlib\\artist.py:337\u001b[0m, in \u001b[0;36mArtist.get_tightbbox\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_tightbbox\u001b[39m(\u001b[38;5;28mself\u001b[39m, renderer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;124;03m    Like `.Artist.get_window_extent`, but includes any clipping.\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;124;03m        The enclosing bounding box (in figure pixel coordinates).\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     bbox \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_window_extent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_clip_on():\n\u001b[0;32m    339\u001b[0m         clip_box \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_clip_box()\n",
      "File \u001b[1;32m~\\opencv\\lib\\site-packages\\matplotlib\\patches.py:602\u001b[0m, in \u001b[0;36mPatch.get_window_extent\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_window_extent\u001b[39m(\u001b[38;5;28mself\u001b[39m, renderer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 602\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_extents\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\opencv\\lib\\site-packages\\matplotlib\\path.py:639\u001b[0m, in \u001b[0;36mPath.get_extents\u001b[1;34m(self, transform, **kwargs)\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;66;03m# as can the ends of the curve\u001b[39;00m\n\u001b[0;32m    638\u001b[0m         xys\u001b[38;5;241m.\u001b[39mappend(curve([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39mdzeros, \u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m--> 639\u001b[0m     xys \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(xys):\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Bbox([xys\u001b[38;5;241m.\u001b[39mmin(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), xys\u001b[38;5;241m.\u001b[39mmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)])\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from PyQt5.QtWidgets import QFileDialog\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import easygui\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=['time', 'emotion'])\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "model= load_model('model.h5')\n",
    "emotion_dict = {0: 'anger', 1: 'contempt', 2: 'disgust',\n",
    "                3: 'fear', 4: 'happiness',\n",
    "                5: 'sadness', 6: 'surprise'}\n",
    "\n",
    "j = 0\n",
    "\n",
    "print('\\n Select your choice: ')\n",
    "print('\\n 1) Capture live feed using webcam')\n",
    "print('\\n 2) Select a video file ')\n",
    "print('\\n 3) Select a image file ')\n",
    "print('\\n Enter Your Choice :')\n",
    "\n",
    "choice = int(input('Choice: \\n'))\n",
    "\n",
    "if choice == 1:\n",
    "    cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "elif choice == 2:\n",
    "    path = easygui.fileopenbox(default='*')\n",
    "    cap = cv2.VideoCapture(path)\n",
    "\n",
    "elif choice == 3:\n",
    "    j = 1\n",
    "    pass\n",
    "\n",
    "else:\n",
    "    cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "\n",
    "def convert_image(image):\n",
    "    image_arr = []\n",
    "    pic = cv2.resize(image, (48, 48))\n",
    "    image_arr.append(pic)\n",
    "    image_arr = np.array(image_arr)\n",
    "    image_arr = image_arr.astype('float32')\n",
    "    image_arr /= 255\n",
    "    ans = model.predict_classes(image_arr)[0]\n",
    "    return ans\n",
    "\n",
    "\n",
    "if j == 0:\n",
    "    while cap.isOpened():\n",
    "        time_rec = datetime.now()\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "\n",
    "            gray = cv2.flip(frame, 1)\n",
    "\n",
    "            faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "            for (x, y, w, h) in faces:\n",
    "                cv2.rectangle(gray, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                roi_gray = gray[y:y + h, x:x + w]\n",
    "\n",
    "\n",
    "                prediction = int(convert_image(roi_gray))\n",
    "\n",
    "                emotion = emotion_dict[prediction]\n",
    "\n",
    "                df = df.append({'time': time_rec, 'emotion': emotion}, ignore_index=True)\n",
    "\n",
    "                cv2.putText(gray, emotion, (x + 20, y - 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255),\n",
    "                            2  , cv2.LINE_AA\n",
    "                            )\n",
    "\n",
    "            cv2.namedWindow('Video', cv2.WINDOW_KEEPRATIO)\n",
    "            cv2.imshow('Video', gray)\n",
    "            cv2.resizeWindow('Video', 1000, 600)\n",
    "\n",
    "            if cv2.waitKey(1) == 27:  # press ESC to break\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "else:\n",
    "\n",
    "\n",
    "    path = easygui.fileopenbox(default='*')\n",
    "    gray = cv2.imread(path)\n",
    "    time_rec = datetime.now()\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(gray, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        roi_gray = gray[y:y + h, x:x + w]\n",
    "        prediction = int(convert_image(roi_gray))\n",
    "\n",
    "        emotion = emotion_dict[prediction]\n",
    "\n",
    "        df = df.append({'time': time_rec, 'emotion': emotion}, ignore_index=True)\n",
    "\n",
    "        cv2.putText(gray, emotion, (x + 20, y - 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255),\n",
    "                    2 , cv2.LINE_AA\n",
    "                    )\n",
    "\n",
    "        cv2.namedWindow('Video', cv2.WINDOW_KEEPRATIO)\n",
    "        cv2.imshow('Video', gray)\n",
    "        cv2.resizeWindow('Video', 1000, 600)\n",
    "\n",
    "        if cv2.waitKey(1) == 27:  # press ESC to break\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "emo_data = df.groupby('emotion').size()\n",
    "print(emo_data, '\\n')\n",
    "\n",
    "emotion_dict_count = {'anger': 0, 'contempt': 0, 'disgust': 0,\n",
    "                      'fear': 0, 'happiness': 0,\n",
    "                      'sadness': 0, 'surprise': 0}\n",
    "\n",
    "for i in df['emotion']:\n",
    "    emotion_dict_count[str(i)] += 1\n",
    "\n",
    "emo_count = [x for x in emotion_dict_count.values()]\n",
    "emo_name = [x for x in emotion_dict_count.keys()]\n",
    "\n",
    "\n",
    "for i,j in zip(emo_count, emo_name):\n",
    "    if i == 0:\n",
    "        emo_count.remove(i)\n",
    "        emo_name.remove(j)\n",
    "\n",
    "\n",
    "\n",
    "plt.pie(x=emo_count, labels=emo_name, autopct='%1.2f', startangle=90)\n",
    "\n",
    "# print('\\n emo_count :',emo_count)\n",
    "# print('\\n emo_name :',emo_name)\n",
    "\n",
    "\n",
    "plt.title(\"Emotions Recorded \")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb718d56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
